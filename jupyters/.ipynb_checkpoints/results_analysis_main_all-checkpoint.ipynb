{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89be61c2-f738-4e9a-a577-67d7b94ca348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ æ­£åœ¨è¯»å–æ•°æ®: D:\\App\\Pycharm\\1206MovieSchedulingSimulation\\logs\\main_all\\main_all_evaluation_results.csv\n",
      "âœ… æˆåŠŸåŠ è½½ 120 æ¡è®°å½•ã€‚\n",
      "ðŸ“‚ å›¾ç‰‡å°†ä¿å­˜è‡³: D:\\App\\Pycharm\\1206MovieSchedulingSimulation\\jupyters\\plots\\main_analysis\n",
      "\n",
      "ðŸš€ å¼€å§‹ç»˜åˆ¶é«˜çº§æ„Ÿå›¾è¡¨ï¼Œå…± 30 ä¸ªæ¡ˆä¾‹...\n",
      "------------------------------------------------------------\n",
      "âœ… æ‰€æœ‰é«˜çº§æ„Ÿç»˜å›¾å·²ä¿å­˜è‡³:\n",
      "   D:\\App\\Pycharm\\1206MovieSchedulingSimulation\\jupyters\\plots\\main_analysis\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. ç§‘ç ”ç»˜å›¾é£Žæ ¼é…ç½® (Science/Nature Style)\n",
    "# ==============================================================================\n",
    "def set_pub_style():\n",
    "    # 1. è‡ªåŠ¨æ£€æµ‹ç³»ç»Ÿå¹¶è®¾ç½®æœ€ä½³ä¸­æ–‡å­—ä½“\n",
    "    sys_name = platform.system()\n",
    "    \n",
    "    if sys_name == \"Windows\":\n",
    "        font_list = ['Microsoft YaHei', 'SimHei', 'Arial', 'sans-serif']\n",
    "    elif sys_name == \"Darwin\":\n",
    "        font_list = ['PingFang SC', 'Heiti TC', 'Arial Unicode MS', 'Arial', 'sans-serif']\n",
    "    else:\n",
    "        font_list = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'SimHei', 'Arial', 'sans-serif']\n",
    "        \n",
    "    plt.rcParams['font.family'] = ['sans-serif']\n",
    "    plt.rcParams['font.sans-serif'] = font_list\n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "    \n",
    "    # 2. å­—å·è®¾ç½®\n",
    "    plt.rcParams['axes.titlesize'] = 15\n",
    "    plt.rcParams['axes.labelsize'] = 13\n",
    "    plt.rcParams['xtick.labelsize'] = 11\n",
    "    plt.rcParams['ytick.labelsize'] = 11\n",
    "    plt.rcParams['legend.fontsize'] = 10\n",
    "    \n",
    "    # 3. çº¿æ¡ä¸Žæ¸…æ™°åº¦\n",
    "    plt.rcParams['axes.linewidth'] = 1.2\n",
    "    plt.rcParams['lines.linewidth'] = 2.0\n",
    "    plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "# é…è‰²æ–¹æ¡ˆ\n",
    "COLOR_PALETTE = {\n",
    "    \"SAC\": \"#0C5DA5\",       # Science Blue\n",
    "    \"Efficiency\": \"#00B945\",# Green\n",
    "    \"Static\": \"#FF9500\",    # Orange\n",
    "    \"Greedy\": \"#845B97\",    # Purple\n",
    "    \"Ref\": \"#555555\"        # Gray\n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. æ•°æ®åŠ è½½å‡½æ•° (ä½¿ç”¨é»‘é©¬æ–‡ä»¶çš„è·¯å¾„é€»è¾‘)\n",
    "# ==============================================================================\n",
    "def load_data(csv_path='logs/main_all/main_all_evaluation_results.csv'):\n",
    "    \"\"\"è¯»å–CSVå¹¶è§£æžJSONåˆ—\"\"\"\n",
    "    try:\n",
    "        current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "    # è·¯å¾„ä¼˜å…ˆæŒ‡å‘ logs/black_horse/\n",
    "    possible_paths = [\n",
    "        csv_path, \n",
    "        os.path.join(current_dir, csv_path),\n",
    "        os.path.join(current_dir, 'logs', 'main_all', 'main_all_evaluation_results.csv'),\n",
    "        # å¤‡ç”¨ï¼šä¹Ÿæœä¸€ä¸‹ evaluation_all ä»¥é˜²ä¸‡ä¸€\n",
    "        os.path.join(current_dir, 'logs', 'evaluation_all', 'main_all_evaluation_results.csv'),\n",
    "        os.path.join(os.path.dirname(current_dir), 'logs','main', 'main_all_evaluation_results.csv')\n",
    "    ]\n",
    "    \n",
    "    found_path = None\n",
    "    for p in possible_paths:\n",
    "        if os.path.exists(p):\n",
    "            found_path = p\n",
    "            break\n",
    "            \n",
    "    if not found_path:\n",
    "        print(f\"âŒ é”™è¯¯ï¼šåœ¨ä»¥ä¸‹è·¯å¾„å‡æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶:\\n{possible_paths}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"ðŸ“‚ æ­£åœ¨è¯»å–æ•°æ®: {found_path}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(found_path, encoding='utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            df = pd.read_csv(found_path, encoding='gbk')\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¯»å–å¤±è´¥: {e}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    # è§£æž JSON\n",
    "    for col in ['daily_actions', 'daily_incomes']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: json.loads(x) if isinstance(x, str) else x)\n",
    "    \n",
    "    if 'case_study_index' in df.columns:\n",
    "        df['case_study_index'] = pd.to_numeric(df['case_study_index'], errors='coerce')\n",
    "\n",
    "    print(f\"âœ… æˆåŠŸåŠ è½½ {len(df)} æ¡è®°å½•ã€‚\")\n",
    "    return df\n",
    "\n",
    "# ==============================================================================\n",
    "# 2. ç”µå½±åˆ†ç±»åå•\n",
    "# ==============================================================================\n",
    "# é»‘é©¬ï¼šä½Žå¼€é«˜èµ°ï¼Œå…³æ³¨ 20% é˜ˆå€¼\n",
    "DARK_HORSE_MOVIES = [\n",
    "    'æµæµªåœ°çƒ', 'ç†Šå‡ºæ²¡Â·åŽŸå§‹æ—¶ä»£', 'æ–°å–œå‰§ä¹‹çŽ‹',\n",
    "    'åˆºæ€å°è¯´å®¶', 'äººæ½®æ±¹æ¶Œ', 'ç†Šå‡ºæ²¡Â·ç‹‚é‡Žå¤§é™†',\n",
    "    'è¿™ä¸ªæ€æ‰‹ä¸å¤ªå†·é™', 'ç†Šå‡ºæ²¡Â·é‡è¿”åœ°çƒ', 'ç‹™å‡»æ‰‹', 'å››æµ·',\n",
    "    'ç†Šå‡ºæ²¡Â·ä¼´æˆ‘â€œç†ŠèŠ¯â€', 'æ— å', 'æ·±æµ·', 'ç¬¬äºŒåæ¡', 'ç†Šå‡ºæ²¡Â·é€†è½¬æ—¶ç©º',\n",
    "    'æˆ‘å’Œæˆ‘çš„çˆ¶è¾ˆ', 'åšå¦‚ç£çŸ³', 'å‰ä»»4ï¼šè‹±å¹´æ—©å©š', 'å¿—æ„¿å†›ï¼šé›„å…µå‡ºå‡»', 'èŽ«æ–¯ç§‘è¡ŒåŠ¨',\n",
    "    'æ‚¬å´–ä¹‹ä¸Š', 'äººç”Ÿè·¯ä¸ç†Ÿ', 'æœ«è·¯ç‹‚èŠ±é’±', 'ä¹é¾™åŸŽå¯¨ä¹‹å›´åŸŽ',\n",
    "    'å°ç¥žç¬¬ä¸€éƒ¨ï¼šæœæ­Œé£Žäº‘', 'é•¿å®‰ä¸‰ä¸‡é‡Œ', 'å­¦çˆ¸', 'å¼‚å½¢ï¼šå¤ºå‘½èˆ°',\n",
    "    'æ¯”æ‚²ä¼¤æ›´æ‚²ä¼¤çš„æ•…äº‹', 'æˆ‘çš„å§å§', 'æ‰¬åç«‹ä¸‡', 'é‡‘æ‰‹æŒ‡', 'å‘¨å¤„é™¤ä¸‰å®³', 'ä½ æƒ³æ´»å‡ºæ€Žæ ·çš„äººç”Ÿ'\n",
    "]\n",
    "\n",
    "# çƒ‚ç‰‡/é«˜å¼€ä½Žèµ°ï¼šé«˜å¼€ä½Žèµ°ï¼Œå…³æ³¨ 10% é˜ˆå€¼\n",
    "ROTTEN_MOVIES = [\n",
    "    'å“†å•¦Aæ¢¦ï¼šå¤§é›„çš„æœˆçƒæŽ¢é™©è®°', 'ä¸Šæµ·å ¡åž’', 'å°Q',\n",
    "    'å¤šåŠ›ç‰¹çš„å¥‡å¹»å†’é™©', 'å–‹è¡€æˆ˜å£«', 'æŠµè¾¾ä¹‹è°œ', '1917', 'æ•°ç å®è´å¤§å†’é™©ï¼šæœ€åŽçš„è¿›åŒ–', \n",
    "    'åœ°ç‹±ç”·çˆµï¼šè¡€çš‡åŽå´›èµ·', 'ä¸€ç§’é’Ÿ',\n",
    "    'çŒ«å’Œè€é¼ ', 'ä½ å¥½ä¸–ç•Œ', 'äº†ä¸èµ·çš„è€çˆ¸', 'æˆ‘æ²¡è°ˆå®Œçš„é‚£åœºæ‹çˆ±', 'é©å‘½è€…', 'æ¢…è‰³èŠ³', 'é“é“è‹±é›„',\n",
    "    'é»‘å®¢å¸å›½ï¼šçŸ©é˜µé‡å¯', 'ç¥žç§˜æµ·åŸŸ', 'ç²¾çµæ—…ç¤¾4ï¼šå˜èº«å¤§å†’é™©', 'è¾¹ç¼˜è¡Œè€…', 'äº¡å‘½æ•‘æŠ¤è½¦', \n",
    "    'å“†å•¦Aæ¢¦ï¼šå¤§é›„çš„å®‡å®™å°æˆ˜äº‰2021', 'ä¸€å‘¨çš„æœ‹å‹',\n",
    "    'ä¸èƒ½æµæ³ªçš„æ‚²ä¼¤', 'å“†å•¦Aæ¢¦ï¼šå¤§é›„ä¸Žå¤©ç©ºçš„ç†æƒ³ä¹¡', 'å¤©ç©ºä¹‹åŸŽ', 'å¿µå¿µç›¸å¿˜',\n",
    "    'å“†å•¦Aæ¢¦ï¼šå¤§é›„çš„åœ°çƒäº¤å“ä¹', 'æŽ’çƒå°‘å¹´!! åžƒåœ¾åœºå†³æˆ˜', 'å¼‚äººä¹‹ä¸‹'\n",
    "]\n",
    "\n",
    "# ==============================================================================\n",
    "# 3. ä¸»åˆ†æžé€»è¾‘ (èžåˆç‰ˆ)\n",
    "# ==============================================================================\n",
    "def analyze_and_plot_merged():\n",
    "    set_pub_style()\n",
    "    df = load_data()\n",
    "    if df.empty: return\n",
    "\n",
    "    try:\n",
    "        current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    except NameError:\n",
    "        current_dir = os.getcwd()\n",
    "\n",
    "    # åˆ›å»ºä¿å­˜ç›®å½•\n",
    "    plots_dir = os.path.join(current_dir, 'plots', 'main_analysis')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    print(f\"ðŸ“‚ å›¾ç‰‡å°†ä¿å­˜è‡³: {plots_dir}\")\n",
    "\n",
    "    unique_cases = df[['start_date', 'case_study_movie']].drop_duplicates()\n",
    "    print(f\"\\nðŸš€ å¼€å§‹ç»˜åˆ¶é«˜çº§æ„Ÿå›¾è¡¨ï¼Œå…± {len(unique_cases)} ä¸ªæ¡ˆä¾‹...\")\n",
    "\n",
    "    PLOT_DAYS = 20\n",
    "\n",
    "    for _, row in unique_cases.iterrows():\n",
    "        date = row['start_date']\n",
    "        movie = row['case_study_movie']\n",
    "        \n",
    "        # --- æ™ºèƒ½åˆ¤æ–­ç»˜å›¾å‚æ•° ---\n",
    "        if movie in DARK_HORSE_MOVIES:\n",
    "            category = \"Black Horse\"\n",
    "            threshold_val = 20.0     # 20%\n",
    "            threshold_label = \"Capture (20%)\"\n",
    "            title_suffix = \"(Black Horse)\"\n",
    "            legend_loc = \"upper left\" # é»‘é©¬å›¾ä¾‹æ”¾å·¦ä¸Š\n",
    "        elif movie in ROTTEN_MOVIES:\n",
    "            category = \"Rotten/Flop\"\n",
    "            threshold_val = 10.0     # 10%\n",
    "            threshold_label = \"Stop Loss (10%)\"\n",
    "            title_suffix = \"(High Start, Low Finish)\"\n",
    "            legend_loc = \"upper right\" # çƒ‚ç‰‡å›¾ä¾‹æ”¾å³ä¸Š\n",
    "        else:\n",
    "            # å¦‚æžœéƒ½ä¸åœ¨åå•é‡Œï¼Œé»˜è®¤æŒ‰é»‘é©¬å¤„ç†ï¼Œæˆ–è€…è·³è¿‡\n",
    "            continue\n",
    "\n",
    "        case_df = df[(df['start_date'] == date) & (df['case_study_movie'] == movie)].copy()\n",
    "        if case_df.empty: continue\n",
    "            \n",
    "        print(f\"ðŸŽ¨ ç»˜å›¾: ã€Š{movie}ã€‹ - [{category}]\")\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        \n",
    "        policy_map = {\n",
    "            \"RL (SAC)\": {\"label\": \"Ours (SAC)\", \"color\": COLOR_PALETTE[\"SAC\"], \"z\": 10},\n",
    "            \"æ•ˆçŽ‡å¯å‘å¼ç­–ç•¥\": {\"label\": \"Efficiency\", \"color\": COLOR_PALETTE[\"Efficiency\"], \"z\": 3},\n",
    "            \"é™æ€å¯å‘å¼ç­–ç•¥\": {\"label\": \"Static\", \"color\": COLOR_PALETTE[\"Static\"], \"z\": 2},\n",
    "            \"è´ªå©ªå¯å‘å¼ç­–ç•¥\": {\"label\": \"Greedy\", \"color\": COLOR_PALETTE[\"Greedy\"], \"z\": 2}\n",
    "        }\n",
    "        \n",
    "        policies = case_df['policy'].unique()\n",
    "        \n",
    "        for policy_name in policies:\n",
    "            if policy_name not in policy_map: continue\n",
    "\n",
    "            run = case_df[case_df['policy'] == policy_name].iloc[0]\n",
    "            idx = run['case_study_index']\n",
    "            if pd.isna(idx): continue\n",
    "            idx = int(idx)\n",
    "            \n",
    "            actions = run['daily_actions']\n",
    "            \n",
    "            y_values = []\n",
    "            for day_act in actions[:PLOT_DAYS]:\n",
    "                if len(day_act) > idx:\n",
    "                    y_values.append(day_act[idx] * 100) \n",
    "                else:\n",
    "                    y_values.append(0)\n",
    "            \n",
    "            x_values = range(1, len(y_values) + 1)\n",
    "            \n",
    "            style = policy_map.get(policy_name, {\"label\": policy_name, \"color\": \"#333333\", \"z\": 1})\n",
    "            lw = 2.5 if \"SAC\" in policy_name else 1.8\n",
    "            \n",
    "            ax.plot(x_values, y_values, \n",
    "                    label=style[\"label\"], \n",
    "                    color=style[\"color\"], \n",
    "                    linewidth=lw, \n",
    "                    alpha=0.9, \n",
    "                    zorder=style[\"z\"])\n",
    "\n",
    "        # --- é«˜çº§æ„Ÿä¿®é¥° ---\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_linewidth(1.2)\n",
    "        ax.spines['bottom'].set_linewidth(1.2)\n",
    "\n",
    "        # åŠ¨æ€ç»˜åˆ¶é˜ˆå€¼çº¿\n",
    "        ax.axhline(y=threshold_val, color=COLOR_PALETTE[\"Ref\"], linestyle=':', linewidth=1.5, alpha=0.6)\n",
    "        \n",
    "        # åŠ¨æ€è°ƒæ•´é˜ˆå€¼æ–‡æœ¬ä½ç½® (é¿å…å’Œæ›²çº¿é‡å )\n",
    "        text_y_offset = 1.0 if category == \"Black Horse\" else 1.5\n",
    "        ax.text(PLOT_DAYS, threshold_val + text_y_offset, f' {threshold_label}', \n",
    "                color=COLOR_PALETTE[\"Ref\"], fontsize=9, va='bottom', ha='right', fontweight='bold')\n",
    "        \n",
    "        ax.set_title(f\"Case Study: {movie}\\n{title_suffix}\", fontsize=14, fontweight='bold', pad=10)\n",
    "        ax.set_xlabel(\"Days Since Release\", fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel(\"Screening Share (%)\", fontsize=12, fontweight='bold')\n",
    "        \n",
    "        ax.set_xlim(1, PLOT_DAYS)\n",
    "        ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "        \n",
    "        # ç»Ÿä¸€è§†é‡Ž 0-100%\n",
    "        ax.set_ylim(bottom=-2, top=102)\n",
    "        \n",
    "        ax.grid(True, linestyle='--', color='#E0E0E0', alpha=0.8, zorder=0)\n",
    "        \n",
    "        # åŠ¨æ€è®¾ç½®å›¾ä¾‹ä½ç½®\n",
    "        ax.legend(frameon=False, loc=legend_loc, fontsize=10)\n",
    "        \n",
    "        # ä¿å­˜\n",
    "        safe_name = movie.replace('Â·', '').replace('ï¼š', '').replace(':', '').replace(' ', '')\n",
    "        filename = f\"{safe_name}_{category.replace(' ', '_').replace('/', '_')}.png\"\n",
    "        save_path = os.path.join(plots_dir, filename)\n",
    "        \n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "        plt.show(fig) \n",
    "        plt.close(fig) \n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"âœ… æ‰€æœ‰é«˜çº§æ„Ÿç»˜å›¾å·²ä¿å­˜è‡³:\\n   {plots_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_and_plot_merged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415ce662-a6bc-41f0-bcd7-b0b2c2cfe723",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 74\u001b[0m\n\u001b[0;32m     71\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     72\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 74\u001b[0m analyze_revenue_structure(\u001b[43mdf\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06689c5b-242b-48ef-a539-3fa5f09dbeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d161f27-92d4-46e9-ac86-e9aac184c946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3cc9f2-a8cd-4f43-a771-d086013b0936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a02289-7b9d-46b6-b445-b3116e432165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b57778-cd61-4a22-afe7-b8853e9a7e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
